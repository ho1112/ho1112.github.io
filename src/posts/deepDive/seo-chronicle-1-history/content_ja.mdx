---
title: 'SEOの過去、現在、そして未来 | アルゴリズム戦争：Google vs ブラックハット #1'
desc: 「SEOは死んだ？」AI時代の検索を理解するために、Googleの20年間の戦争史を振り返ります。PageRankの誕生からBMW追放事件、パンダとペンギンアップデートまで。アルゴリズムを欺こうとする者(ブラックハット)と守ろうとする者(Google)の熾烈な攻防戦を取り上げます。
date: 2025-11-25
thumbnail: /posts/deepDive/seo-chronicle-1-history/thumbnail.avif
---

## SEO is dead?

![](/posts/deepDive/seo-chronicle-1-history/seo-dead.avif)

**SEOは死んだ。**

AI時代が幕を開け、周囲で頻繁に耳にする言葉です。しかし、開発者である私にとってSEOは終わった技術ではなく、時代に合わせて変化し続けている領域だと考えています。

私はフロントエンドエンジニアとして働きながら、社内のSEO改善チームで活動した経験があります。
普段は特定の機能やページ単位の開発に集中していましたが、SEOチームではサービス全体の構造を改善したり、検索ターゲットとなるコンテンツを作成したりするなど、よりマクロな視点での作業を行いました。これはフロントエンドエンジニアとして視野を広げる上で大きな資産となりました。

何より、フロントエンド開発の核心であり基本であるCore Web Vitalsを集中的に改善してみることで、技術的な最適化が実際のビジネス成果につながる過程を深く経験することができました。
そんな中、最近AIが登場し、GEO(Generative Engine Optimization)という聞き慣れない概念が聞こえてくると、ある一つの考えが浮かび始めました。
「検索のパラダイムが変わろうとしているが、果たしてフロントエンド開発にはどのような変化が起こるのだろうか？これまでとは全く異なる方式の対応が必要な時点が来たのではないだろうか？」

このような問いを投げかけているうちに、自然と現在の検索エンジンがどのような過程を経てここまで来たのか気になり始めました。突然登場したGEOという概念を正しく理解するためには、Googleが過去20年間ウェブエコシステムをどのように構築してきたのか、その流れをまず振り返ってみることが役立つと考えました。
そこで、個人的な好奇心から始まった学習内容をもとに、1990年代の混沌からAI時代の幕開けまで、検索の進化過程を3部作としてまとめてみようと思います。

その第一弾は、**アルゴリズムを欺こうとする人間と、それを阻止しようとするGoogleの戦争**についての物語です。

---

## チャプター1. キーワードマッチングの限界とGoogleの登場

### 初期の検索エンジンの限界(1990年代後半)

もし1990年代後半のインターネットを覚えていますか？インターネットは爆発的に膨張していましたが、当時の検索エンジンであるアルタビスタ(AltaVista)、ヤフー(Yahoo!)、ライコス(Lycos)はこの速度に追いつけずにいました。
当時の検索エンジンの動作方式は非常に原始的でした。唯一の基準は、ユーザーが入力した単語がページにどれだけ多く含まれているか？(Keyword Density：キーワード出現頻度)でした。

![altavista 1997年の姿](/posts/deepDive/seo-chronicle-1-history/altavista-1997.avif)
![yahoo 1997年の姿](/posts/deepDive/seo-chronicle-1-history/yahoo-1997.avif)

開発者の視点から見ると、まるでDBで `LIKE '%keyword%'` 条件でデータを照会した後、単純にマッチした単語の個数(Count)が多い順にソートして表示するロジックと変わりありませんでした。
例えば「自動車」を検索すると、自動車に関する深みのあるコラムより、背景色と同じ白いフォントで「自動車」という単語だけを5,000回コピーして貼り付けたスパムサイトが1位に上がりました。図書館に行ったのに、司書が本の内容は見ずに「この本に『自動車』という単語が一番多く出てきますね」と言って落書き帳を渡してくるようなものでした。

情報は溢れていましたが、肝心の欲しい情報は探せなかったこの混沌を鎮めたのは、スタンフォード大学寮の大学院生、ラリー・ペイジ(Larry Page)とセルゲイ・ブリン(Sergey Brin)でした。
![Larry Page / Sergey Brin](/posts/deepDive/seo-chronicle-1-history/래리페이지_세르게이브린.webp)

彼らは1996年、ウェブページのリンク関係を分析する新しい検索エンジンプロジェクトを開始しました。初期の名前はバックラブ(BackRub)でしたが、すぐに **Google(グーグル)** という名前で世に知られることになります。
そして、新興企業だったGoogleが既存の巨大検索エンジンを抜いて市場を掌握できた決定的な武器、それがまさにページランク(PageRank)でした。

---

## チャプター2. PageRankの数学的原理

ラリー・ペイジとセルゲイ・ブリンは、既存エンジンの単純さに限界を感じていました。彼らは学界の論文引用索引(Citation Index)から重要なヒントを得ます。
> Academic citation literature has been applied to the web, largely by counting citations or backlinks to a given page. ... PageRank extends this idea by not counting links from all pages equally...
> *「学術文献の引用(Citation)の概念をウェブに適用しました... PageRankは、すべてのリンクを同等にカウントしないことで、このアイデアを拡張しました。」*
[The anatomy of a large-scale hypertextual Web search engine(1998)](https://share.google/8L6bl8arI2lENmQaF)

つまり、権威ある論文に多く引用されるほど良い論文であるという学界の評価方式を、ウェブサイトのリンク構造にそのまま適用することにしたのです。
この仮説が現代の検索エンジンの根幹となったページランク(PageRank)アルゴリズムを誕生させました。

### 1. リンクは投票だ(Link is a Vote)
既存のエンジンがページ内部(On-page)のテキストだけを分析していた時、Googleはページ外部(Off-page)の関係を分析しました。AサイトがBサイトへリンクを貼ると、Googleはこれを「AがBを信頼している」という投票とみなしました。

### 2. 不平等な投票権(Weighted Voting)
しかし、ここで民主主義とは異なる決定的な違いが発生します。すべての投票が平等ではないという点です。

* 私の友人のブログが私をリンクすること(重み 1)
* ホワイトハウスのホームページ(.gov)が私をリンクすること(重み 100,000)

Googleは単純にリンクの数(Quantity)ではなく、リンクを貼ったサイトの権威(Quality)を数学的に計算しました。「権威あるサイトが推薦したサイトは権威がある」という再帰的(Recursive)な論理です。

### 3. ランダムサーファー(Random Surfer)モデルとダンピングファクター
この論理を数学的に完成させたのが、あの有名なPageRankの公式です。

![](/posts/deepDive/seo-chronicle-1-history/Summation_Formula.svg)

* $PR(A)$: ページAのページランクスコア
* $d$ (Damping Factor): 通常0.85に設定されるこの定数は、ランダムサーファーモデルの核心です。

![](/posts/deepDive/seo-chronicle-1-history/PageRanks-Example.svg)
ランダムサーファーモデルとは、インターネットをサーフィンする仮想のユーザーがランダムにリンクをクリックしながら回る状況を仮定したものです。ユーザーはずっとリンクを辿って移動しますが、ある瞬間に退屈してサーフィンを止めたり、他のアドレスを入力したりします。その確率がまさに $d$(0.85) です。

このアルゴリズムの登場により、スパムサイトは順位圏外へと追いやられ、Googleは検索市場の王座を占めることになります。

![Googleの成長とアルタビスタの没落](/posts/deepDive/seo-chronicle-1-history/altavista-google.webp)

---

## チャプター3. アルゴリズムの盲点：ブラックハット(Black Hat)手法の登場

ページランクの登場で検索品質は飛躍的に向上しましたが、同時にこのアルゴリズムの盲点を突く試みも当然生まれました。これをブラックハット(Black Hat)SEOと呼びます。

「ブラックハット」という用語は西部劇に由来しています。映画の中で主人公が「白い帽子(White Hat)」を被っていたのに対し、悪党は常に「黒い帽子(Black Hat)」を被って登場したことから取られた表現です。つまり、検索エンジンが決めたルール(ガイドライン)を破り、不正な方法で順位を操作する手法を意味します。
![black hat](/posts/deepDive/seo-chronicle-1-history/blackhat.avif)

当時のマーケターや開発者たちは、正当なコンテンツ競争の代わりにシステムを欺いて上位表示を勝ち取るため、4つの代表的な迂回手法を積極的に活用しました。

### 1. キーワードスタフィング(Keyword Stuffing)と隠蔽
最も原始的な方法です。検索エンジンが「キーワード密度」を見るという点を悪用し、文脈に関係なくキーワードを無限に詰め込む(Stuffing)ことです。しかし、ユーザーが見るには汚らしいため、彼らはCSSを利用してテキストを隠す技術へと進化しました。

```css
/* ブラックハットの隠蔽術の例 */
.hidden-text {
  text-indent: -9999px; /* 画面外へテキストを押し出す */
  font-size: 0;         /* フォントサイズ 0 */
  color: white;         /* 背景色と同じに */
  display: none;        /* 完全に隠す */
}
```
* **原理:** Google Bot(Crawler)はHTMLソースを読むため、これらのキーワードをすべて認識しますが、実際の人間の目にはきれいな画面だけが見えます。

### 2. リンクファーム(Link Farm)
ページランクアルゴリズムを無力化するための方法です。互いに何の関係もない数千のウェブサイトを開設し、互いに互いをクモの巣のようにリンクし合う偽のネットワークを構築することです。
* **原理:** AサイトがBを、BがCを、Cが再びAをリンクします。こうすれば実際には何の価値もないサイトたちですが、互いに「投票(リンク)」をやり取りし、ページランクの点数を人為的に水増しすることができます。

### 3. クローキング(Cloaking)
技術的に最も高度化された手法の一つです。「マントを羽織る(Cloak)」という語源のように、接続する主体によって互いに異なるコンテンツを提供(Serving)する方式です。

* **原理:** サーバーはクライアントの接続リクエストが入ってくると `User-Agent` やIPアドレスを確認します。もしGooglebotなら検索最適化されたページを応答し、一般ユーザーならギャンブルやアダルトサイトへリダイレクトします。これは検索エンジンを欺く行為であるため、摘発された場合は検索結果から永久に削除(De-index)されるなど、プラットフォームレベルでの最も強力な制裁が科されます。

### 4. ドアウェイページ(Doorway Pages)
ひたすら検索結果に露出するために作られた偽のドア(Door)です。
* **原理:** 「ソウル ホテル」、「東京 ホテル」、「ニューヨーク ホテル」... 地域名だけを変えた数百のページを作ります。ユーザーが検索して入ってくると、自動的に本来の目的であるショッピングモールへリダイレクト(Redirect)させたり、巨大なリンク一つだけをぽつんと表示したりします。情報は無く、トラフィックを吸い上げるための通路の役割だけをするページです。

これら4つの代表的な手法以外にも、自動化プログラムで他人の文章を巧みに変える**記事スピニング(Article Spinning)**、ブログのコメントにリンクを埋め尽くす**コメントスパム(Comment Spam)** など、数多くの手法が横行しました。

---

## チャプター4. インターネットの釣り記事

このようなブラックハット技術は、単に機械的な操作にとどまりませんでした。人々の好奇心を悪用する釣り文化も共に発展しました。一度くらいは経験があるかと思います。

### 「いかがでしたか？」ブログ
日本のウェブエコシステムも同様でした。検索結果の上段を占領したいわゆるトレンドブログが社会的問題になりました。
刺激的なタイトル(「〇〇〇の年収公開！結婚相手は？」)でクリックを誘導しますが、内容は挨拶と広告だけです。そして最後はいつもこの文句で終わります。

![いかがでしたか 検索被害 - https://note.com/pand_panda/n/n9d89609a68ca](/posts/deepDive/seo-chronicle-1-history/いかかでしたか.webp)

> **「調べてみましたが分かりませんでした！いかがでしたか？」**

また、漫画やアニメを違法に探そうとする人々を狙った **`zip`, `rar`, `raw`** キーワード釣りも盛んに行われました。ダウンロードリンクを押すとファイルの代わりにマルウェアが待ち受けていたりしましたね。

---

## チャプター5. 検索品質の再定義：システム的対応とアルゴリズムアップデート

Googleはこのような状況を解決するために、個別のサイトを制裁する方式だけでは限界があることを認識し、検索アルゴリズムの評価基準自体を大々的に改編し始めました。
この時断行された二度のアップデートが、まさに現代SEOの基盤を築いた **パンダ(Panda)** と **ペンギン(Penguin)** アップデートです。

### [Case Study 1] 技術で欺く：BMW追放事件(2006)
![https://www.pinsentmasons.com/out-law/news/google-removes-bmwde-over-optimisation-tactic](/posts/deepDive/seo-chronicle-1-history/bmw.avif)
2006年、BMWのドイツサイト(bmw.de)は「中古車」キーワードで上位表示させるために、ドアウェイページとクローキング技術を使用しました。
Google Botには中古車という単語で溢れたページを見せ、人間には華やかな画像ページへ移動させる方式でした。
これを摘発したGoogleは、即座にBMWのホームページを検索インデックスから削除(De-index)措置しました。これは大企業であってもガイドラインに違反すれば例外なく制裁を受けるという事実を見せつけた象徴的な事件でした。

### [Case Study 2] 金で買う：J.C. Penney事件(2011)
![https://searchengineland.com/new-york-times-exposes-j-c-penney-link-scheme-that-causes-plummeting-rankings-in-google-64529](/posts/deepDive/seo-chronicle-1-history/jcpenny_link.avif)
BMWが技術で欺いたとすれば、アメリカの巨大百貨店 J.C. Penneyはリンクファームを利用してアルゴリズムを買収しようとしました。
2010年のショッピングシーズン、彼らはDresses、Beddingなど数千のキーワードで1位を占めました。しかしニューヨーク・タイムズの調査報道により、彼らが核工学サイト、カジノサイトなど雑多なウェブサイトに金を払ってリンクを植え付けていた事実が発覚しました。
Googleは直ちに手動措置を下し、1位だったJ.C. Penneyの順位は68位へと急落しました。

### [Algorithm Update] パンダとペンギンの登場
個別サイトの処罰を超え、Googleはアルゴリズム自体を進化させました。

#### 🐼 パンダアップデート(Panda Update, 2011)
パンダの目標は明確でした。まさに「コンテンツファーム(Content Farm)」でした。
当時eHowのような会社はフリーランサーを雇い、検索量は多いが質は低い「中身のない記事」を1日に数千個ずつ生産していました。

Googleはこれを解決するために機械学習(Machine Learning)を導入しました。人間が直接評価したデータを学習させ、「何が人間にとって有用な文章か？」を機械が自ら判断するようにしたのです。

* **主な取り締まり対象:** 内容が乏しい記事、記事より広告が多いページ、複製されたコンテンツ。
* **結果:** Googleの公式発表によると、全検索結果の約 **11.8%** が変動するという大きな変化がありました。コンテンツファームのトラフィックは激減し、「量」より「質」が重要だという認識が定着し始めました。
出典: [Google Official Blog (2011)](https://googleblog.blogspot.com/2011/02/finding-more-high-quality-sites-in.html)

#### 🐧 ペンギンアップデート(Penguin Update, 2012)
パンダが「記事の内容」を見たなら、ペンギンはリンクの真正性を掘り下げました。
ペンギンアルゴリズムはリンクを貼る際に使用するアンカーテキスト(Anchor Text)のパターンを分析しました。

自然な推薦なら「このブログ」、「出典」、「こちら」など多様な単語が使用されるはずです。しかし順位操作を狙ったサイトは [「最安値ローン」、「最安値ローン」...] のように商業的キーワードだけを繰り返す不自然なパターンを見せました。ペンギンはこれを機械的なスパムと判定しました。

* **主な取り締まり対象:** 有料リンク購入、リンクファーム、不自然なアンカーテキスト。
* **結果:** 全英語検索語の約 **3.1%** に影響を及ぼしました。数値上は小さく見えますが、これまでブラックハットで順位を維持していたサイトが大挙して検索結果から消え、SEO業界に大きな衝撃を与えました。
出典: [Google Search Central Blog (2012)](https://developers.google.com/search/blog/2012/04/another-step-to-reward-high-quality)

![blackhat out!](/posts/deepDive/seo-chronicle-1-history/panda_penguin.avif)

ちなみにパンダは動物のパンダではなく、Googleのエンジニア、ナブニート・パンダ(Navneet Panda)の名前から取ったそうです。[Google_Panda wiki](https://en.wikipedia.org/wiki/Google_Panda)
その後もGoogle Hummingbird、Google Pigeonのように、Google検索エンジンは動物の名前で命名されています。<small>草創期のAndroidのように、Googleはシリーズで名前を付けるのが好きなようですね</small>

---

## おわりに

これまで1990年代の混乱の時期からパンダ、ペンギンアップデートに至るまで、約20年間続いた検索アルゴリズムの進化過程を見てきました。

初期の検索エンジンは単純にキーワードの頻度数に依存していましたが、次第にリンクの信頼度とコンテンツの品質を評価する方向へと高度化されました。
かつてはアルゴリズムの盲点を突く「ブラックハット」手法が通用したかもしれませんが、機械学習とAIが導入された現在の環境では、もはや単純な技術的迂回では上位表示を保証されなくなりました。

この時期を経てSEOの中心軸は、「検索順位」そのものからウェブサイトが提供するユーザー体験(User Experience)と技術的完成度へと完全に移動しました。これがまさに現代のSEOがマーケティング領域を超え、フロントエンド開発の領域と密接になった理由だと考えます。
次の第2部では、このような流れの中で開発者が具体的にどのような役割を果たしたのか、Core Web Vitalsと構造化データを中心に話を続けていきます。

---

#### 参考文献およびおすすめ資料
* [The anatomy of a large-scale hypertextual Web search engine(1998)](https://share.google/8L6bl8arI2lENmQaF)
* [Google removes BMW.de over optimisation tactic](https://www.pinsentmasons.com/out-law/news/google-removes-bmwde-over-optimisation-tactic)
* [PageRank wikipedia](https://en.wikipedia.org/wiki/PageRank)
* [New York Times Exposes J.C. Penney Link Scheme That Causes Plummeting Rankings in Google (2011)](https://searchengineland.com/new-york-times-exposes-j-c-penney-link-scheme-that-causes-plummeting-rankings-in-google-64529)
* [Google Search Central: Spam Policies](https://developers.google.com/search/docs/essentials/spam-policies)
* [Finding more high-quality sites in search](https://googleblog.blogspot.com/2011/02/finding-more-high-quality-sites-in.html)
* [Another step to reward high-quality sites](https://developers.google.com/search/blog/2012/04/another-step-to-reward-high-quality)