---
title: '사진 한 장으로 장소를 알려주는 LINE AI봇 개발기 (with Gemini)'
desc: 사진 한 장으로 장소를 알려주는 LINE AI봇 개발기 (with Gemini)
date: 2025-07-07
thumbnail: /posts/codeLab/pixelWalkers/pixelWalkers.avif
---

# LINE과 Gemini AI로 이미지 인식 LINE봇 만들기

## 프롤로그: 일단 뭐라도 해보자

![楽天証券](/posts/codeLab/pixelWalkers/rakuten.avif)
![SBI証券](/posts/codeLab/pixelWalkers/sbi.avif)

처음 LINE봇을 만드려고 생각한 것은 개인적인 목표에서 시작되었습니다. 바로 **"SBI 증권 계좌에 배당금이 입금될 때마다 자동으로 그 내역을 LINE으로 알려주는 봇"**을 만드는 것이었죠.
playwright와 GAS를 조합하면 자동으로 로그인->배당금 내역 취득->LINE으로 전송까지 가능할 것 같았습니다. 하지만 최근 보안이 강화되면서 2단계 인증(2FA)이 필수가 되면서 그 처리가 다소 복잡해졌습니다
단순한 로그인이 아니라 복잡한 인증 요소까지 돌파해야했고 혹시나 부정 액세스로 계정이 차단당할 위험이 있을 수도 있기에 일단 이건 계획 단계에서 중단했습니다.

그래도 LINE봇을 만들어보자라고 생각했으니 그 방향을 유지하고 다른 아이디어를 생각해보았습니다.
그러다 문득 평소에 산책할 때 저게 뭐지? 하면서 궁금했던 장소들이 있었기에 이런 생각이 들었습니다.
"LINE으로 그냥 사진만 찍어 보내면 AI가 알아서 그게 뭔지 알려주면 어떨까?"

그래서 일단 시작해봤습니다.

***

## 1. 설계와 준비: 어떤 기술로 만들까?

가장 먼저 어떤 기술들을 조합할지 결정해야 했습니다.

일단 가장 익숙한 Next.js로 만들고 배포가 간편한 Vercel을 사용하기로 했습니다. Geminai API는 Google AI Studio에서 발급받았습니다.

* **인터페이스:** **`LINE Messaging API`**
    * 별도의 앱 개발 없이 가장 친숙한 사용자 경험을 제공하기 위해 선택했습니다.
* **서버:** **`Next.js (App Router) API Route`**
    * 파일 기반 라우팅으로 간단하게 서버리스 API 엔드포인트를 구축할 수 있습니다.
* **AI 모델:** **`Google Gemini 2.5 Flash (Vision)`**
    * 강력한 멀티모달(이미지+텍스트) 분석 성능과 편리한 API를 제공합니다.
* **배포:** **`Vercel`**
    * Next.js, GitHub와 연동하여 자동 배포(CI/CD)를 지원합니다.

#### **데이터 흐름**
[LINE User (image)] → [LINE Platform] → Webhook (POST) → [Vercel Endpoint] → [Gemini API] → [Vercel Endpoint] → Reply API → [LINE Platform] → [LINE User]

***

## 2. 프로젝트 설정 및 핵심 의존성

프로젝트는 `create-next-app`으로 시작하고 AI와 LINE의 연동을 위해 두 개의 라이브러리를 설치했습니다.

1.  **Next.js 프로젝트 생성:**
    ```bash
    npx create-next-app@latest pixel-walkers --ts --eslint --app
    ```
2.  **핵심 라이브러리 설치:**
    ```bash
    npm install @google/generative-ai @line/bot-sdk
    ```
    * **`@google/generative-ai`**: Gemini API와 통신하기 위한 Google 공식 SDK입니다.
    * **`@line/bot-sdk`**: Webhook 요청 처리와 메시지 발송 등 LINE Messaging API를 쉽게 사용하기 위한 공식 SDK입니다.

API 키와 같은 민감 정보는 `.env.local` 파일에 안전하게 보관하고, `.gitignore`에 등록하여 GitHub에 노출되지 않도록 처리했습니다.

```env
# Google AI Studio
GEMINI_API_KEY=""

# LINE Developers
LINE_CHANNEL_ACCESS_TOKEN=""
LINE_CHANNEL_SECRET=""
```

***

## 3. LINE봇 생성과 웹훅(Webhook)

아이디어를 구현하기 위해 가장 먼저 LINE Developers 콘솔에서 봇을 만들어야 했습니다. 우선 프로바이더를 만들고 채널를 생성하였습니다. 채널 생성 후 갑자기 **manager.line.biz**라는 관리자 페이지로 이동하였습니다.
채널을 생성한 **developers.line.biz**는 저희 개발자들이 다루는 곳이고 manager.line.biz는 마케팅 담당자/라인 채널 담당자가 관리하는 곳인 것 같습니다. 프로필 사진을 여기서 설정해줄 수 있습니다.
![developers.line.biz](/posts/codeLab/pixelWalkers/lineDev.avif)
우여곡절 끝에 봇을 생성하고 API 키들을 발급받은 뒤 다음 관문인 **웹훅(Webhook)** 을 마주했습니다. 웹훅은 'LINE 서버'가 제 '개발 서버'에게 메시지를 전달해주는 통로입니다.

LINE채널의 이름은 `PixelWalkers`라고 지어주었습니다. 우선 첫 번째 메시지로 'hi'를 보내보았습니다.
![](/posts/codeLab/pixelWalkers/firstMessage.avif)
메시지를 보내자 기본 설정된 자동 응답 메시지가 잘 도착했습니다. 이걸로 Messaging API 초기 설정은 완료!

저는 이 '통로'가 제대로 뚫렸는지 확인하기 위해 두 가지 도구를 사용했습니다.

![webhook.site](/posts/codeLab/pixelWalkers/webhooksite.avif)
1.  **`webhook.site`:** 코드를 짜기 전, LINE이 정말로 신호를 보내주는지 확인하기 위한 임시 웹훅 주소 서비스입니다. 여기에 제 봇을 연결하고 라인 메시지를 보내니 JSON 데이터가 화면에 나타났고 전송한 메시지를 확인할 수 있었습니다.
![ngrok](/posts/codeLab/pixelWalkers/ngrok.avif)
2.  **`ngrok`:** 이제 제 실제 코드와 연결할 차례였습니다. 배포 전 로컬에서 확인할 필요가 있기 때문에 외부에서 접속할 `ngrok`이라는 터널이 필요했습니다. `npm install -g ngrok`으로 설치하고 `ngrok http 3000`을 실행하니 제 로컬환경으로 향하는 임시 주소가 생겼습니다.

***

## 4. 핵심 로직 심층 분석: Webhook API

여러차례 디버깅을 거친 끝에 안정적으로 작동하는 `app/api/webhook/route.ts` 코드가 완성되었습니다.

```typescript
// ... (필요한 import문들)

// ... (환경 변수 및 클라이언트 초기화)

// ... (streamToBuffer 헬퍼 함수)

// LINE으로부터 POST 요청을 받는 메인 핸들러
export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const events: WebhookEvent[] = body.events;

    // 여러 이벤트를 동시에 안정적으로 처리하기 위해 Promise.all 사용
    const results = await Promise.all(
      events.map(async (event) => {
        const userId = event.source?.userId;
        const replyToken = event.type === 'message' ? event.replyToken : undefined;

        try {
          if (!userId || !replyToken) {
            return; // 처리할 수 없는 이벤트는 그냥 넘어감
          }

          // 이미지 메시지일 때만 로직 실행
          if (event.type === 'message' && event.message.type === 'image') {
            // 1. 사용자 언어 정보 조회
            // LINE公式アカウントをブロックしているユーザーのプロフィール情報は取得できません。 --> 취득 못하는 경우도 있음 (기본값 'ja')
            let userLanguage = 'ja';
            try {
              const profile = await lineClient.getProfile(userId);
              if (profile.language) {
                userLanguage = profile.language;
              }
              console.log('언어 ', userLanguage)
            } catch {
              console.error(`프로필 조회 실패 (user: ${userId})`);
            }

            // 2. 이미지 분석 및 답장 보내기
            const responseStream = await lineClient.getMessageContent(event.message.id);
            const buffer = await streamToBuffer(responseStream as unknown as Stream);
            const imageBase64 = buffer.toString('base64');

            const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });
            const prompt = `You are a helpful and friendly tour guide. Your tone should be engaging and informative.
            Analyze the user's image.
            Identify the landmark, object, or place in the image.
            If it is a famous place or object, provide a concise but engaging paragraph (about 4-5 sentences) that includes its key characteristics, a fun fact, or its historical significance.
            If you cannot identify it, state that clearly and describe what you see.
            VERY IMPORTANT: You MUST write your entire response in the following language code: ${userLanguage}`;
            const result = await model.generateContent([
              prompt, { inlineData: { data: imageBase64, mimeType: 'image/jpeg' } }
            ]);
            const aiResponseText = result.response.text();

            await lineClient.replyMessage(replyToken, { type: 'text', text: aiResponseText });
          }
        } catch (error) {
          console.error('개별 이벤트 처리 중 에러 발생:', error);
          // 3. 에러 발생 시, 사용자에게 에러 메시지 답장
          if (replyToken) {
            const errorMessage = "申し訳ありません、一時的なエラーが発生しました。しばらくしてからもう一度お試しください。\n\n죄송합니다, 일시적인 오류가 발생했습니다. 잠시 후 다시 시도해주세요.\n\nSorry, a temporary error occurred. Please try again later.";
            await lineClient.replyMessage(replyToken, { type: 'text', text: errorMessage });
          }
        }
      })
    );
    return NextResponse.json({ status: 'ok', results });
  } catch (error) {
    if (error instanceof Error) console.error('전체 요청 처리 중 에러 발생:', error.message);
    return NextResponse.json({ status: 'error' }, { status: 500 });
  }
}
```

### 코드 해설: PixelWalkers는 어떻게 작동하는가?
위 코드는 몇 가지 핵심적인 로직을 통해 작동합니다.

![](/posts/codeLab/pixelWalkers/language.avif)
**동적 다국어 처리**: lineClient.getProfile(userId)를 통해 사용자의 LINE 앱 언어 설정을 직접 조회합니다. 만약 조회가 실패하더라도 기본 언어(일본어)로 안정적으로 작동하도록 설계했습니다. 이 userLanguage 변수를 Gemini 프롬프트에 포함시켜서 AI가 사용자의 언어에 맞춰 답변을 생성하도록 지시합니다. 기본값은 일본어입니다.

**이미지 메시지만을 위한 로직 필터링**: if (event.message.type === 'image') 조건문이 '수문장' 역할을 합니다. 오직 사용자가 이미지를 보냈을 경우에만 AI 분석 로직이 실행되며 텍스트나 스티커 등 다른 타입의 메시지는 무시하여 불필요한 API 호출을 막습니다.

![](/posts/codeLab/pixelWalkers/error.avif)
**안정적인 서비스를 위한 예외/에러 응답**: 각 사용자의 이벤트를 개별 try...catch 블록으로 감쌌습니다. 이를 통해 한 사용자의 요청에서 API 할당량 초과 등의 에러가 발생하더라도 다른 사용자에게 영향을 주지 않고 서비스 전체가 중단되는 것을 방지합니다. 또한 에러 발생 시 사용자에게 다국어로 된 안내 메시지를 보내 봇이 멈춘 것이 아님을 알려주는 친절함도 추가했습니다.

![](/posts/codeLab/pixelWalkers/noLandmark.avif)
**해석 할 수 없는 이미지**: 장소, 랜드마크 등 AI가 해석할 수 없는 사진인 경우에는 해당 이미지의 분석 결과를 전송합니다.


## 5. 배포:vercel
완성된 소스코드를 github에 push하고 vercel에 연동하여 배포하였습니다.
![](/posts/codeLab/pixelWalkers/vercel.avif)

배포가 완료되면 도메인이 생성됩니다. 도메인을 복사하여 LINE Developers의 webhook에 넣어줍니다.
검증버튼을 눌러 연결됐는지 확인합니다!
![](/posts/codeLab/pixelWalkers/webhookSuccess.avif)

## 6. LINE:PixelWalkers
이제 배포가 완료 되었습니다. LINE에서 확인해봅니다.
시부야의 하치코와 오차노미즈의 히지리바시 사진을 전송해보았습니다.
![하치코](/posts/codeLab/pixelWalkers/hachiko_ko.avif)
![히지리바시](/posts/codeLab/pixelWalkers/hijiribashi_ko.avif)
성공!

## 마무리하며
Part 1 완료.
이번 프로젝트는 단순히 코드를 작성하는 것을 넘어 'Gemini'라는 뛰어난 잠재력을 가진 팀원과 함께 일하는 경험과도 같았습니다. 이 팀원은 방대한 지식과 뛰어난 추론 능력을 가졌지만 때로는 엉뚱한 거짓말(환각)을 하거나 맥락을 잘못 이해하기도 했습니다.
저의 역할은 이 AI 팀원의 장점은 극대화하고 단점은 보완하는 '리더'의 역할이었습니다. 명확한 지시서(프롬프트 엔지니어링)를 통해 목표를 설정해주고 외부 세계와 소통할 수 있는 손과 발(LINE API, 외부 API 연동)을 만들어주었으며 예상치 못한 행동(에러)에 대비하는 안정적인 업무 환경(에러 핸들링)을 구축했습니다.
이 과정을 통해 최신 기술을 단순한 '도구'로 사용하는 것을 넘어 그 특성을 깊이 이해하고 목표에 맞게 '매니지먼트'하여 실질적인 가치를 창출하는 것이 중요하다고 생각합니다. Part 2에서도 이 AI 팀원과 함께 완성도 높은 LINE봇으로 성장시켜 나갈 계획입니다.

**💡 추가로 해보고 싶은 것들:**
* **채팅 제한:** 이미지 입력 외에는 처리하지 않기 때문에 사용자의 채팅 입력이 있을 경우, 응답할 수 없다는 코멘트를 전송
* **로딩 애니메이션:** 이미지 입력 후 응답이 도착하기 전까지 로딩 애니메이션 보여주기([LINE 공식문서](https://developers.line.biz/ja/docs/messaging-api/use-loading-indicator/#example-request))
* **프롬프트 토큰 측정:** 프롬프트를 영어, 일본어, 한국어로 변경해보면서 영어의 토큰 수가 유의미하게 절약되는지 테스트
